{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOtEm+CTrhk8LZ/Ux6RGwdx"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from google.colab import files\n","uploaded = files.upload()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":73},"id":"ZhW7MZg7YoWF","executionInfo":{"status":"ok","timestamp":1675623343488,"user_tz":-60,"elapsed":16923,"user":{"displayName":"Aleksy The Horse","userId":"16196062761541124387"}},"outputId":"5b469c6f-7948-4588-fd1f-d24c1b370bc2"},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-f775cc8f-db8e-49e1-9b6a-d8d204d3e229\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-f775cc8f-db8e-49e1-9b6a-d8d204d3e229\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving train.csv to train.csv\n"]}]},{"cell_type":"code","execution_count":8,"metadata":{"id":"aa9jDbMuCH-o","colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"status":"ok","timestamp":1675623353694,"user_tz":-60,"elapsed":236,"user":{"displayName":"Aleksy The Horse","userId":"16196062761541124387"}},"outputId":"481fd2e1-9247-4cf0-9494-1c8d4b2ffefc"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["   PassengerId  Survived  Pclass  \\\n","0            1         0       3   \n","1            2         1       1   \n","2            3         1       3   \n","3            4         1       1   \n","4            5         0       3   \n","\n","                                                Name     Sex   Age  SibSp  \\\n","0                            Braund, Mr. Owen Harris    male  22.0      1   \n","1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n","2                             Heikkinen, Miss. Laina  female  26.0      0   \n","3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n","4                           Allen, Mr. William Henry    male  35.0      0   \n","\n","   Parch            Ticket     Fare Cabin Embarked  \n","0      0         A/5 21171   7.2500   NaN        S  \n","1      0          PC 17599  71.2833   C85        C  \n","2      0  STON/O2. 3101282   7.9250   NaN        S  \n","3      0            113803  53.1000  C123        S  \n","4      0            373450   8.0500   NaN        S  "],"text/html":["\n","  <div id=\"df-7da064dc-8cc0-417c-ab4d-7571df030f7d\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>PassengerId</th>\n","      <th>Survived</th>\n","      <th>Pclass</th>\n","      <th>Name</th>\n","      <th>Sex</th>\n","      <th>Age</th>\n","      <th>SibSp</th>\n","      <th>Parch</th>\n","      <th>Ticket</th>\n","      <th>Fare</th>\n","      <th>Cabin</th>\n","      <th>Embarked</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>Braund, Mr. Owen Harris</td>\n","      <td>male</td>\n","      <td>22.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>A/5 21171</td>\n","      <td>7.2500</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n","      <td>female</td>\n","      <td>38.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>PC 17599</td>\n","      <td>71.2833</td>\n","      <td>C85</td>\n","      <td>C</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>Heikkinen, Miss. Laina</td>\n","      <td>female</td>\n","      <td>26.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>STON/O2. 3101282</td>\n","      <td>7.9250</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n","      <td>female</td>\n","      <td>35.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>113803</td>\n","      <td>53.1000</td>\n","      <td>C123</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>Allen, Mr. William Henry</td>\n","      <td>male</td>\n","      <td>35.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>373450</td>\n","      <td>8.0500</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7da064dc-8cc0-417c-ab4d-7571df030f7d')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-7da064dc-8cc0-417c-ab4d-7571df030f7d button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-7da064dc-8cc0-417c-ab4d-7571df030f7d');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":8}],"source":["train_data = pd.read_csv(\"train.csv\")\n","train_data.head()"]},{"cell_type":"code","source":["test_data = pd.read_csv(\"/kaggle/input/titanic/test.csv\")\n","test_data.head()\n","pass_id = test_data.PassengerId"],"metadata":{"id":"O9rN2uTHYTyF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_data.describe()"],"metadata":{"id":"NJvLqrDWYWDe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_data = pd.read_csv(\"/kaggle/input/titanic/test.csv\")\n","test_data.head()"],"metadata":{"id":"JOTROA2lYXrd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from scipy.stats.stats import pearsonr\n","\n","print(\"Correlations\")\n","age_data = pd.get_dummies(train_data[[\"Survived\", \"Age\"]])\n","age_mean = age_data['Age'].mean()\n","age_data_drop = age_data.dropna()\n","corr = pearsonr(age_data_drop[\"Survived\"], age_data_drop[\"Age\"])\n","print(\"Raw age: \", corr)\n","\n","age_data['Age'].fillna(value=age_mean, inplace=True)\n","corr = pearsonr(age_data[\"Survived\"], age_data[\"Age\"])\n","print(\"Filled age: \", corr)\n","\n","correlated_columns = [\"Pclass\", \"SibSp\", \"Parch\", \"Fare\"]\n","for name in correlated_columns:\n","    corr = pearsonr(train_data['Survived'], train_data[name])\n","    print(name, \": \", corr)"],"metadata":{"id":"KOgbp2cbYZEl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","from sklearn.pipeline import Pipeline\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.linear_model import SGDClassifier, LogisticRegression\n","from sklearn.svm import SVC\n","from sklearn.metrics import f1_score\n","from sklearn.ensemble import AdaBoostClassifier\n","import statistics as st\n","\n","features = [\"Pclass\", \"Sex\", \"Fare\", \"Parch\", \"Age\"]\n","age_mean = train_data['Age'].mean()\n","train_data[\"Age\"].fillna(value=age_mean, inplace=True)\n","X_all = pd.get_dummies(train_data)\n","X = pd.get_dummies(train_data[features])\n","y = train_data[\"Survived\"]\n","\n","model_names = [\"forest\", \"SVC\", \"logic\"]\n","forest_train = []\n","forest_test = []\n","sgd_train = []\n","sgd_test = []\n","svc_train = []\n","svc_test = []\n","logic_train = []\n","logic_test = []\n","\n","for i in range (10):\n","    X_train, X_test, y_train, y_test=train_test_split(X,y,train_size=0.8)\n","    \n","    pipe = Pipeline([(\"scaler\", StandardScaler()),\n","      (\"model\", RandomForestClassifier(n_estimators=100, max_depth=8))])\n","    pipe.fit(X_train, y_train)\n","    forest_train.append(f1_score(pipe.predict(X_train), y_train))\n","    forest_test.append(f1_score(pipe.predict(X_test), y_test))\n","\n","    pipe = Pipeline([(\"scaler\", StandardScaler()),\n","      (\"model\", SVC())])\n","    pipe.fit(X_train, y_train)\n","    svc_train.append(f1_score(pipe.predict(X_train), y_train))\n","    svc_test.append(f1_score(pipe.predict(X_test), y_test))\n","\n","    pipe = Pipeline([(\"scaler\", StandardScaler()),\n","      (\"model\", LogisticRegression(solver='lbfgs', max_iter=200))])\n","    pipe.fit(X_train, y_train)\n","    logic_train.append(f1_score(pipe.predict(X_train), y_train))\n","    logic_test.append(f1_score(pipe.predict(X_test), y_test))\n","\n","for name in model_names:\n","    if name == \"forest\":\n","        train = forest_train\n","        test = forest_test\n","    elif name == \"SVC\":\n","        train = svc_train\n","        test = svc_test\n","    elif name == \"logic\":\n","        train = logic_train\n","        test = logic_test\n","        \n","    print(name)\n","    print(\"training score\")\n","    print(\"Min: \", min(train))\n","    print(\"Max: \", max(train))\n","    print(\"Mean: \", st.mean(train))\n","    print(\"testing score\")\n","    print(\"Min: \", min(test))\n","    print(\"Max: \", max(test))\n","    print(\"Mean: \", st.mean(test))\n","    print(\"\")"],"metadata":{"id":"8MUVKRlBYakY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Ensamble time!\n","from sklearn import model_selection\n","from sklearn.ensemble import VotingClassifier\n","\n","fold = model_selection.KFold(n_splits=5, shuffle=True)\n","estimators = []\n","estimators.append((\"forest\", \n","          RandomForestClassifier(n_estimators=100, max_depth=8)))\n","estimators.append((\"svc\", SVC()))\n","estimators.append((\"logic\", \n","                  LogisticRegression(solver='lbfgs', max_iter=150)))\n","ensamble = VotingClassifier(estimators)\n","fin = model_selection.cross_val_score(ensemble, X, y, cv=fold)\n","print(fin.mean())\n","ensamble.fit(X_train,y_train)\n","print(f1_score(ensamble.predict(X_test), y_test))\n","ensamble.fit(X,y)\n","print(f1_score(ensamble.predict(X_test), y_test))\n","\n","fare_mean = test_data['Fare'].mean()\n","test_data[\"Fare\"].fillna(value=fare_mean, inplace=True)\n","age_mean_test = test_data['Age'].mean()\n","test_data[\"Age\"].fillna(value=age_mean_test, inplace=True)\n","test_data = pd.get_dummies(test_data[features])\n","\n","predictions = ensamble.predict(test_data)\n","output = pd.DataFrame({'PassengerId': pass_id, 'Survived': predictions})\n","output.to_csv('submission.csv', index=False)"],"metadata":{"id":"WznZuQBCYcgf"},"execution_count":null,"outputs":[]}]}